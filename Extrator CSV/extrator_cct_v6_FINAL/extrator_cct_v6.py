#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Extrator de Dados de Conven√ß√µes Coletivas de Trabalho (CCTs) - Vers√£o 6
Autor: Manus AI
Descri√ß√£o: Vers√£o com PyMuPDF, normaliza√ß√£o completa do sindicato e limpeza rigorosa de artefatos
"""

import os
import re
import csv
import argparse
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import fitz  # PyMuPDF
from openai import OpenAI

# Configura√ß√£o do cliente OpenAI (usa vari√°veis de ambiente pr√©-configuradas)
client = OpenAI()


class ExtratorCCT:
    """Classe para extrair dados de PDFs de Conven√ß√µes Coletivas de Trabalho"""
    
    def __init__(self, pdf_path: str, usar_ia: bool = True, modelo: str = "gpt-4.1-mini"):
        """
        Inicializa o extrator
        
        Args:
            pdf_path: Caminho para o arquivo PDF
            usar_ia: Se True, usa IA para gerar resumos autom√°ticos
            modelo: Modelo de IA a ser usado (gpt-4.1-mini, gpt-4.1-nano, gemini-2.5-flash)
        """
        self.pdf_path = pdf_path
        self.usar_ia = usar_ia
        self.modelo = modelo
        self.texto_completo = ""
        self.sindicato = ""
        self.convencao = ""
        self.clausulas = []
        
    def extrair_texto_pdf(self) -> str:
        """
        Extrai texto do PDF usando PyMuPDF (melhor qualidade)
        
        Returns:
            Texto completo extra√≠do do PDF
        """
        print(f"üìÑ Extraindo texto do PDF: {self.pdf_path}")
        texto_completo = []
        
        try:
            doc = fitz.open(self.pdf_path)
            
            for i, page in enumerate(doc, 1):
                texto = page.get_text()
                if texto:
                    texto_completo.append(texto)
                    print(f"   ‚úì P√°gina {i}/{len(doc)} extra√≠da")
                else:
                    print(f"   ‚ö† P√°gina {i}/{len(doc)} sem texto extra√≠vel")
            
            doc.close()
            
            self.texto_completo = "\n".join(texto_completo)
            print(f"‚úì Extra√ß√£o conclu√≠da: {len(self.texto_completo)} caracteres\n")
            return self.texto_completo
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair texto do PDF: {e}")
            raise
    
    def normalizar_sindicato(self, sindicato_bruto: str) -> str:
        """
        Normaliza o nome do sindicato corrigindo erros de OCR
        
        Args:
            sindicato_bruto: Nome do sindicato com erros de OCR
            
        Returns:
            Nome normalizado
        """
        # Remove quebras de linha
        sindicato = ' '.join(sindicato_bruto.split())
        
        # Corre√ß√µes espec√≠ficas de OCR no nome do sindicato
        correcoes_sindicato = {
            # Corre√ß√£o de "slNDlcATo" para "SlNDlCATO"
            r'[sS][lI1][NnMm][DdOo][lI1][cCGg][Aa√Ä√°][Tt√ç√≠][OoQq0]': 'SlNDlCATO',
            
            # Corre√ß√£o de "Dos" para "DOS"
            r'\bDos\b': 'DOS',
            r'\bDo\b': 'DO',
            
            # Corre√ß√£o de "M√âDtcos" para "M√âDICOS"
            r'[MmNn][√â√©Ee][DdOo][tT√≠√çiI1][cCGg][oOQq0][sS]': 'M√âDICOS',
            
            # Corre√ß√£o de "BAHTA" para "BAHIA"
            r'\bBAHTA\b': 'BAHIA',
            
            # Corre√ß√£o de "S|NDIMED" para "SINDIMED"
            r'S\|NDIMED': 'SINDIMED',
            r'S\|ND[IilL1]MED': 'SINDIMED',
        }
        
        for padrao, substituicao in correcoes_sindicato.items():
            sindicato = re.sub(padrao, substituicao, sindicato)
        
        # Garante capitaliza√ß√£o correta de palavras-chave
        sindicato = sindicato.upper()
        
        # Corre√ß√µes finais
        sindicato = sindicato.replace('SLNDICATO', 'SINDICATO')
        sindicato = sindicato.replace('SLNDLCATO', 'SINDICATO')
        
        return sindicato.strip()
    
    def identificar_sindicato_convencao(self) -> Tuple[str, str]:
        """
        Identifica o sindicato DOS EMPREGADOS e o per√≠odo da conven√ß√£o no texto
        
        Returns:
            Tupla (sindicato, conven√ß√£o)
        """
        print("üîç Identificando sindicato e conven√ß√£o...")
        
        linhas_iniciais = self.texto_completo[:3000]
        
        # Estrat√©gia 1: Buscar sindicato dos empregados no cabe√ßalho
        padrao_empregado = r'(?:do outro lado|e,?\s+do outro lado)\s+[oa]\s+([Ss][lI1][NnMm][DdOo][lI1][cCGg][Aa√Ä√°][Tt√ç√≠][OoQq0].*?(?:SINDIMED|S\|NDIMED)).*?(?:,\s+sito|,\s+CNPJ|,\s+neste)'
        match_empregado = re.search(padrao_empregado, linhas_iniciais, re.IGNORECASE | re.DOTALL)
        
        if match_empregado:
            sindicato_bruto = match_empregado.group(1).strip()
            # Normaliza o sindicato corrigindo erros de OCR
            self.sindicato = self.normalizar_sindicato(sindicato_bruto)
            print(f"   ‚úì Sindicato encontrado e normalizado")
        
        # Estrat√©gia 2: Buscar apenas SINDIMED com contexto
        if not self.sindicato:
            padrao_sindimed = r'([Ss][lI1][NnMm][DdOo][lI1][cCGg][Aa√Ä√°][Tt√ç√≠][OoQq0]\s+[DdOo][OoQq0][Ss]\s+[MmNn][√â√©Ee][DdOo][tT√≠√çiI1][cCGg][oOQq0][sS].*?(?:SINDIMED|S\|NDIMED))'
            match_sindimed = re.search(padrao_sindimed, linhas_iniciais)
            
            if match_sindimed:
                sindicato_bruto = match_sindimed.group(1)
                self.sindicato = self.normalizar_sindicato(sindicato_bruto)
                print(f"   ‚úì Sindicato encontrado e normalizado")
        
        # Estrat√©gia 3: Buscar no corpo do texto (fallback)
        if not self.sindicato:
            padrao_corpo = r'(?:representados pelo|pelo)\s+(Sindicato\s+dos?\s+[A-Z√Ä-√ø\s]+?(?:SINDIMED|[-‚Äì]\s*SINDIMED))'
            match_corpo = re.search(padrao_corpo, linhas_iniciais, re.IGNORECASE)
            
            if match_corpo:
                sindicato_bruto = match_corpo.group(1).strip()
                self.sindicato = self.normalizar_sindicato(sindicato_bruto)
                print(f"   ‚úì Sindicato encontrado (fallback)")
        
        # Padr√£o para per√≠odo/ano da conven√ß√£o
        padrao_periodo = r'(?:CONVEN√á√ÉO\s+COLETIVA.*?)?(\d{4}[-/tl]\d{4})'
        match_periodo = re.search(padrao_periodo, linhas_iniciais, re.IGNORECASE)
        
        if match_periodo:
            periodo_bruto = match_periodo.group(1)
            # Normaliza separadores
            self.convencao = periodo_bruto.replace('/', '-').replace('t', '-').replace('l', '-')
        else:
            padrao_ano = r'(\d{4})'
            anos = re.findall(padrao_ano, linhas_iniciais)
            if len(anos) >= 2:
                self.convencao = f"{anos[0]}-{anos[1]}"
            elif len(anos) == 1:
                self.convencao = anos[0]
        
        # Fallback: usa nome do arquivo
        if not self.sindicato or not self.convencao:
            nome_arquivo = Path(self.pdf_path).stem
            if not self.convencao:
                match_ano_arquivo = re.search(r'(\d{4}[-/]?\d{4})', nome_arquivo)
                if match_ano_arquivo:
                    self.convencao = match_ano_arquivo.group(1).replace('/', '-')
        
        if not self.sindicato:
            self.sindicato = "SINDICATO N√ÉO IDENTIFICADO"
        if not self.convencao:
            self.convencao = "ANO N√ÉO IDENTIFICADO"
        
        print(f"   Sindicato: {self.sindicato}")
        print(f"   Conven√ß√£o: {self.convencao}\n")
        
        return self.sindicato, self.convencao
    
    def limpar_artefatos(self, texto: str) -> str:
        """
        Remove artefatos e caracteres estranhos do texto extra√≠do
        
        Args:
            texto: Texto com poss√≠veis artefatos
            
        Returns:
            Texto limpo
        """
        # Remove linhas com apenas 1-3 caracteres isolados (artefatos comuns)
        linhas = texto.split('\n')
        linhas_limpas = []
        
        for linha in linhas:
            linha_strip = linha.strip()
            
            # Ignora linhas que s√£o claramente artefatos
            if linha_strip and not re.match(r'^[A-Z],\w+$', linha_strip):  # Remove "A,l"
                if linha_strip not in ['w', '¬´', '¬ª', '4-', '/-', '.0', '141']:  # Remove artefatos conhecidos
                    if not re.match(r'^\d+-?$', linha_strip):  # Remove n√∫meros isolados com h√≠fen
                        if len(linha_strip) > 1 or linha_strip.isalnum():  # Mant√©m apenas se > 1 char ou alfanum√©rico
                            linhas_limpas.append(linha)
        
        texto_limpo = '\n'.join(linhas_limpas)
        
        # Remove m√∫ltiplas quebras de linha
        texto_limpo = re.sub(r'\n{3,}', '\n\n', texto_limpo)
        
        # Remove espa√ßos m√∫ltiplos
        texto_limpo = re.sub(r' {2,}', ' ', texto_limpo)
        
        return texto_limpo
    
    def corrigir_ocr_texto(self, texto: str) -> str:
        """
        Corrige erros comuns de OCR no texto extra√≠do
        
        Args:
            texto: Texto com poss√≠veis erros de OCR
            
        Returns:
            Texto corrigido
        """
        # Dicion√°rio de corre√ß√µes de OCR comuns
        correcoes_ocr = {
            # Corre√ß√£o de datas mal formatadas
            r'\babrill?(\d{4})\b': r'abril/\1',
            r'\bmaiol?(\d{4})\b': r'maio/\1',
            r'\bjunhol?(\d{4})\b': r'junho/\1',
            r'\bjulhol?(\d{4})\b': r'julho/\1',
            r'\bagostol?(\d{4})\b': r'agosto/\1',
            r'\bsetemb?rol?(\d{4})\b': r'setembro/\1',
            r'\boutubl?rol?(\d{4})\b': r'outubro/\1',
            r'\bnovembl?rol?(\d{4})\b': r'novembro/\1',
            r'\bdezembl?rol?(\d{4})\b': r'dezembro/\1',
            r'\bjaneirl?ol?(\d{4})\b': r'janeiro/\1',
            r'\bfevereirl?ol?(\d{4})\b': r'fevereiro/\1',
            r'\bmar√ßol?(\d{4})\b': r'mar√ßo/\1',
            
            # Corre√ß√£o de datas com caracteres estranhos
            r'\bmaiot2O2\'': 'maio/2025',
            r'\bjulhol2025': 'julho/2025',
            r'\bagosto/2O25': 'agosto/2025',
            r'\bsetembro/2O25': 'setembro/2025',
            r'\boutubro/2O25': 'outubro/2025',
            
            # Corre√ß√£o de anos com O em vez de 0
            r'/2O(\d{2})\b': r'/20\1',
            r'\b2O(\d{2})\b': r'20\1',
            
            # Corre√ß√£o de n√∫meros com l em vez de 1
            r'\bl2(\d{3})\b': r'1/2\1',
            
            # Corre√ß√£o de "√≠orma" para "forma"
            r'\b√≠orma\b': 'forma',
            
            # Corre√ß√£o de "per√çodo" para "per√≠odo"
            r'\bper√çodo\b': 'per√≠odo',
            
            # Corre√ß√£o de "tr√¢nsfer√™ncia" para "transfer√™ncia"
            r'\btr√¢nsfer√™ncia\b': 'transfer√™ncia',
            
            # Corre√ß√£o de "ess√™s" para "esses"
            r'\bess√™s\b': 'esses',
            
            # Corre√ß√£o de espa√ßos antes de pontua√ß√£o
            r'\s+([,\.;:!?])': r'\1',
            
            # Corre√ß√£o de m√∫ltiplos espa√ßos
            r'\s{2,}': ' ',
        }
        
        # Aplica todas as corre√ß√µes
        texto_corrigido = texto
        for padrao, substituicao in correcoes_ocr.items():
            texto_corrigido = re.sub(padrao, substituicao, texto_corrigido, flags=re.IGNORECASE)
        
        return texto_corrigido
    
    def normalizar_titulo_clausula(self, titulo: str) -> str:
        """
        Normaliza o t√≠tulo da cl√°usula para o padr√£o correto
        
        Args:
            titulo: T√≠tulo bruto extra√≠do do PDF
            
        Returns:
            T√≠tulo normalizado no padr√£o correto
        """
        # Remove espa√ßos extras
        titulo = ' '.join(titulo.split())
        
        # Dicion√°rio de corre√ß√µes de erros de OCR e padroniza√ß√£o
        correcoes = {
            # Corre√ß√£o de "CLAUSULA" para "CL√ÅUSULA"
            r'^CLAUSULA\s+': 'CL√ÅUSULA ',
            r'^clausula\s+': 'CL√ÅUSULA ',
            r'^C√∫USULA\s+': 'CL√ÅUSULA ',
            r'^c√∫USULA\s+': 'CL√ÅUSULA ',
            r'^C[√∫u]USULA\s+': 'CL√ÅUSULA ',
            r'^c[√∫u]usula\s+': 'CL√ÅUSULA ',
            
            # Corre√ß√£o de ordinais com erros de OCR
            r'\bOUARTA\b': 'QUARTA',
            r'\bQuarta\b': 'QUARTA',
            r'\boITAVA\b': 'OITAVA',
            r'\bSEGUNOA\b': 'SEGUNDA',
            r'\bo√âcIMA\b': 'D√âCIMA',
            r'\bD√âcIMA\b': 'D√âCIMA',
            r'\bvIG√âSIMA\b': 'VIG√âSIMA',
            r'\bVIGESIMA\b': 'VIG√âSIMA',
            r'\bVIG√âSIUN\b': 'VIG√âSIMA',
            r'\bTRIGESSIMA\b': 'TRIG√âSIMA',
            r'\bTRIG√âSSIMA\b': 'TRIG√âSIMA',
            r'\bQUADRAGESIMA\b': 'QUADRAG√âSIMA',
            r'\bQUADRAG√âSIMA\b': 'QUADRAG√âSIMA',
            r'\bQUINQUAGESIMA\b': 'QUINQUAG√âSIMA',
            r'\bQUINQUAG√âSIMA\b': 'QUINQUAG√âSIMA',
            r'\bOrave\b': 'OITAVA',
            r'\bQUIXTN\b': 'QUINTA',
            
            # Corre√ß√£o de "coMIsS√Éo" para "COMISS√ÉO"
            r'\bcoMIsS√Éo\b': 'COMISS√ÉO',
            r'\bcoMIss√Éo\b': 'COMISS√ÉO',
            
            # Corre√ß√£o de "TR√ÇBALHO" para "TRABALHO"
            r'\bTR√ÇBALHO\b': 'TRABALHO',
            
            # Outras corre√ß√µes
            r'\bALIMENTA√ß√ÉO\b': 'ALIMENTA√á√ÉO',
            r'\bINSALUBRIDAOE\b': 'INSALUBRIDADE',
            r'\bDIRIGEN√çE\b': 'DIRIGENTE',
            r'\bAOICIONAL\b': 'ADICIONAL',
            r'\bAUx√≠LIo\b': 'AUX√çLIO',
            r'\bcREcHE\b': 'CRECHE',
            r'\bF√âRhS\b': 'F√âRIAS',
            r'\bLIBERA√á√ÇO\b': 'LIBERA√á√ÉO',
            r'\bCONDI√ß√îES\b': 'CONDI√á√ïES',
            r'\bATUALIZA√ß√ÉO\b': 'ATUALIZA√á√ÉO',
            r'\bMEDIA√ß√ÉO\b': 'MEDIA√á√ÉO',
            r'\bOEFICI√äNCIA\b': 'DEFICI√äNCIA',
            r'\bPER√≠ODO\b': 'PER√çODO',
            r'\bASS√âOIO\b': 'ASS√âDIO',
            r'\bSETIMA\b': 'S√âTIMA',
            r'\bDECIMA\b': 'D√âCIMA',
        }
        
        # Aplica todas as corre√ß√µes
        for padrao, substituicao in correcoes.items():
            titulo = re.sub(padrao, substituicao, titulo, flags=re.IGNORECASE)
        
        # Remove pontos extras antes do h√≠fen
        titulo = re.sub(r'\s*\.\s*-', ' -', titulo)
        titulo = re.sub(r'\s*\.\s+([A-Z])', r' - \1', titulo)
        
        # Garante que h√° h√≠fen entre o ordinal e o t√≠tulo
        if re.match(r'^CL√ÅUSULA\s+\w+\s+[A-Z]', titulo) and ' - ' not in titulo:
            match = re.match(r'^(CL√ÅUSULA\s+(?:\w+\s+)*\w+)\s+([A-Z])', titulo)
            if match:
                titulo = f"{match.group(1)} - {match.group(2)}{titulo[match.end():]}"
        
        # Capitaliza corretamente
        titulo = titulo.upper()
        
        return titulo.strip()
    
    def extrair_clausulas(self) -> List[Dict[str, str]]:
        """
        Extrai todas as cl√°usulas do texto usando m√∫ltiplas estrat√©gias
        
        Returns:
            Lista de dicion√°rios com dados das cl√°usulas
        """
        print("üìã Extraindo cl√°usulas...")
        
        # Divide o texto em linhas para processamento linha por linha
        linhas = self.texto_completo.split('\n')
        
        clausulas_encontradas = []
        i = 0
        
        while i < len(linhas):
            linha = linhas[i].strip()
            
            # Verifica se a linha come√ßa com varia√ß√µes de "CL√ÅUSULA"
            if re.match(r'^(?:CL[√ÅA√ö√∫a√°u]USULA|cl[√°a√∫u]usula|C[√∫√°aU]USULA|c[√∫√°au]usula)\s+', linha, re.IGNORECASE):
                # Captura o t√≠tulo completo da cl√°usula
                titulo_clausula = linha
                inicio_conteudo = i + 1
                
                # Encontra o fim da cl√°usula (pr√≥xima cl√°usula ou fim do texto)
                j = i + 1
                while j < len(linhas):
                    proxima_linha = linhas[j].strip()
                    if re.match(r'^(?:CL[√ÅA√ö√∫a√°u]USULA|cl[√°a√∫u]usula|C[√∫√°aU]USULA|c[√∫√°au]usula)\s+', proxima_linha, re.IGNORECASE):
                        break
                    j += 1
                
                # Extrai o conte√∫do da cl√°usula
                conteudo_linhas = linhas[inicio_conteudo:j]
                conteudo_completo = '\n'.join(conteudo_linhas).strip()
                
                # Limpa artefatos
                conteudo_completo = self.limpar_artefatos(conteudo_completo)
                
                # Limpa o conte√∫do
                conteudo_completo = self._limpar_conteudo(conteudo_completo)
                
                # Aplica corre√ß√µes de OCR no conte√∫do
                conteudo_completo = self.corrigir_ocr_texto(conteudo_completo)
                
                if conteudo_completo:  # S√≥ adiciona se tiver conte√∫do
                    # Normaliza o t√≠tulo da cl√°usula
                    titulo_normalizado = self.normalizar_titulo_clausula(titulo_clausula)
                    
                    clausulas_encontradas.append({
                        'titulo': titulo_normalizado,
                        'conteudo': conteudo_completo,
                        'linha_inicio': i
                    })
                
                i = j  # Pula para a pr√≥xima cl√°usula
            else:
                i += 1
        
        print(f"   Encontradas {len(clausulas_encontradas)} cl√°usulas\n")
        
        # Processa cada cl√°usula encontrada
        clausulas = []
        for idx, clausula_info in enumerate(clausulas_encontradas, 1):
            titulo = clausula_info['titulo']
            conteudo = clausula_info['conteudo']
            
            # Gera resumo
            if self.usar_ia and conteudo:
                resumo = self._gerar_resumo_ia(titulo, conteudo)
            else:
                resumo = self._gerar_resumo_simples(conteudo)
            
            clausula_dict = {
                'Sindicato': self.sindicato,
                'Conven√ß√£o': self.convencao,
                'T√≠tulo da Cl√°usula': titulo,
                'Resumo': resumo,
                'Cl√°usula Completa': conteudo
            }
            
            clausulas.append(clausula_dict)
            print(f"   ‚úì Cl√°usula {idx}/{len(clausulas_encontradas)}: {titulo[:60]}...")
        
        self.clausulas = clausulas
        print(f"\n‚úì Total de {len(clausulas)} cl√°usulas extra√≠das\n")
        return clausulas
    
    def _limpar_conteudo(self, texto: str) -> str:
        """
        Remove ru√≠dos e formata o conte√∫do da cl√°usula
        
        Args:
            texto: Texto bruto da cl√°usula
            
        Returns:
            Texto limpo
        """
        # Remove m√∫ltiplas quebras de linha
        texto = re.sub(r'\n{3,}', '\n\n', texto)
        
        # Remove linhas com apenas caracteres especiais ou n√∫meros de p√°gina
        linhas = texto.split('\n')
        linhas_limpas = []
        
        for linha in linhas:
            linha_strip = linha.strip()
            # Ignora linhas muito curtas, apenas n√∫meros, ou s√≠mbolos de assinatura
            if len(linha_strip) > 2 and not re.match(r'^[\d\s\-‚Äì‚Äî_\.]+$', linha_strip):
                # Remove s√≠mbolos de assinatura comuns no final do documento
                if not re.search(r'(?:Presidente|Diretor|Salvador,?\s+\d|^\s*[A-Z][a-z]+\s+[A-Z][a-z]+\s*$|^\d{10,}$)', linha_strip):
                    linhas_limpas.append(linha)
        
        texto_limpo = '\n'.join(linhas_limpas).strip()
        
        # Remove espa√ßos m√∫ltiplos
        texto_limpo = re.sub(r' {2,}', ' ', texto_limpo)
        
        # Remove linhas que parecem ser artefatos de assinatura no final
        linhas_finais = texto_limpo.split('\n')
        while linhas_finais and (len(linhas_finais[-1].strip()) < 5 or 
                                 re.match(r'^[^\w\s]+$', linhas_finais[-1].strip())):
            linhas_finais.pop()
        
        texto_limpo = '\n'.join(linhas_finais)
        
        return texto_limpo
    
    def _gerar_resumo_simples(self, conteudo: str) -> str:
        """
        Gera um resumo simples pegando as primeiras frases
        
        Args:
            conteudo: Conte√∫do completo da cl√°usula
            
        Returns:
            Resumo simples
        """
        if len(conteudo) <= 150:
            return conteudo
        
        # Procura o primeiro ponto final
        match_ponto = re.search(r'\.(?:\s|$)', conteudo[:300])
        if match_ponto:
            return conteudo[:match_ponto.end()].strip()
        
        # Fallback: primeiros 150 caracteres + "..."
        return conteudo[:150].strip() + "..."
    
    def _gerar_resumo_ia(self, titulo: str, conteudo: str) -> str:
        """
        Gera resumo usando IA (GPT)
        
        Args:
            titulo: T√≠tulo da cl√°usula
            conteudo: Conte√∫do completo da cl√°usula
            
        Returns:
            Resumo gerado pela IA
        """
        try:
            prompt = f"""Voc√™ √© um especialista em direito trabalhista brasileiro. Analise a seguinte cl√°usula de uma Conven√ß√£o Coletiva de Trabalho e gere um resumo conciso e objetivo em uma √∫nica frase (m√°ximo 200 caracteres).

T√≠tulo: {titulo}

Conte√∫do:
{conteudo[:1500]}

Resumo (uma frase objetiva):"""

            response = client.chat.completions.create(
                model=self.modelo,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em direito trabalhista brasileiro. Gere resumos concisos e objetivos de cl√°usulas de CCTs."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=100
            )
            
            resumo = response.choices[0].message.content.strip()
            
            # Remove aspas se houver
            resumo = resumo.strip('"\'')
            
            # Garante que termina com ponto
            if resumo and not resumo.endswith('.'):
                resumo += '.'
            
            return resumo
            
        except Exception as e:
            print(f"   ‚ö† Erro ao gerar resumo com IA: {e}")
            return self._gerar_resumo_simples(conteudo)
    
    def _limpar_para_csv(self, texto: str) -> str:
        """
        Limpa texto para ser salvo no CSV sem problemas de parsing
        
        Args:
            texto: Texto a ser limpo
            
        Returns:
            Texto limpo e seguro para CSV
        """
        if not isinstance(texto, str):
            return str(texto)
        
        # Remove quebras de linha e substitui por espa√ßo
        texto = texto.replace('\r\n', ' ').replace('\n', ' ').replace('\r', ' ')
        
        # Remove m√∫ltiplos espa√ßos
        texto = ' '.join(texto.split())
        
        # Remove caracteres de controle problem√°ticos
        texto = ''.join(char for char in texto if ord(char) >= 32 or char in '\t\n\r')
        
        return texto.strip()
    
    def salvar_csv(self, output_path: str) -> None:
        """
        Salva as cl√°usulas extra√≠das em arquivo CSV com escape adequado para pandas
        
        Args:
            output_path: Caminho do arquivo CSV de sa√≠da
        """
        print(f"üíæ Salvando dados em CSV: {output_path}")
        
        if not self.clausulas:
            print("‚ùå Nenhuma cl√°usula para salvar!")
            return
        
        try:
            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['Sindicato', 'Conven√ß√£o', 'T√≠tulo da Cl√°usula', 'Resumo', 'Cl√°usula Completa']
                writer = csv.DictWriter(
                    csvfile, 
                    fieldnames=fieldnames,
                    quoting=csv.QUOTE_ALL,  # For√ßa aspas em todos os campos
                    escapechar='\\',  # Caractere de escape
                    doublequote=True  # Duplica aspas internas
                )
                
                writer.writeheader()
                
                # Limpa dados antes de escrever para evitar problemas de parsing
                clausulas_limpas = []
                for clausula in self.clausulas:
                    clausula_limpa = {}
                    for key, value in clausula.items():
                        clausula_limpa[key] = self._limpar_para_csv(value)
                    clausulas_limpas.append(clausula_limpa)
                
                writer.writerows(clausulas_limpas)
            
            print(f"‚úì Arquivo CSV salvo com sucesso!")
            print(f"   Total de linhas: {len(self.clausulas)}")
            print(f"   Tamanho do arquivo: {os.path.getsize(output_path) / 1024:.2f} KB\n")
            
        except Exception as e:
            print(f"‚ùå Erro ao salvar CSV: {e}")
            raise
    
    def processar(self, output_path: str) -> None:
        """
        Executa o processo completo de extra√ß√£o
        
        Args:
            output_path: Caminho do arquivo CSV de sa√≠da
        """
        print("=" * 70)
        print("üöÄ EXTRATOR DE DADOS DE CCTs - VERS√ÉO 6 (PYMUPDF + CLEAN)")
        print("=" * 70)
        print()
        
        # 1. Extrair texto do PDF
        self.extrair_texto_pdf()
        
        # 2. Identificar sindicato e conven√ß√£o
        self.identificar_sindicato_convencao()
        
        # 3. Extrair cl√°usulas
        self.extrair_clausulas()
        
        # 4. Salvar em CSV
        self.salvar_csv(output_path)
        
        print("=" * 70)
        print("‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!")
        print("=" * 70)


def main():
    """Fun√ß√£o principal para execu√ß√£o via linha de comando"""
    parser = argparse.ArgumentParser(
        description='Extrator de Dados de Conven√ß√µes Coletivas de Trabalho (CCTs) - Vers√£o 6',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  
  # Extrair com resumos autom√°ticos (IA):
  python extrator_cct_v6.py input.pdf -o output.csv
  
  # Extrair sem IA (resumos simples, mais r√°pido):
  python extrator_cct_v6.py input.pdf -o output.csv --sem-ia
        """
    )
    
    parser.add_argument('pdf_path', help='Caminho para o arquivo PDF da CCT')
    parser.add_argument('-o', '--output', required=True, help='Caminho para o arquivo CSV de sa√≠da')
    parser.add_argument('--sem-ia', action='store_true', help='N√£o usar IA para gerar resumos (mais r√°pido)')
    parser.add_argument('--modelo', default='gpt-4.1-mini', 
                       choices=['gpt-4.1-mini', 'gpt-4.1-nano', 'gemini-2.5-flash'],
                       help='Modelo de IA a ser usado (padr√£o: gpt-4.1-mini)')
    
    args = parser.parse_args()
    
    # Valida se o arquivo PDF existe
    if not os.path.exists(args.pdf_path):
        print(f"‚ùå Erro: Arquivo PDF n√£o encontrado: {args.pdf_path}")
        return 1
    
    # Cria o extrator e processa
    try:
        extrator = ExtratorCCT(
            pdf_path=args.pdf_path,
            usar_ia=not args.sem_ia,
            modelo=args.modelo
        )
        extrator.processar(args.output)
        return 0
        
    except Exception as e:
        print(f"\n‚ùå ERRO FATAL: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
